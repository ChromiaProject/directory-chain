import ^^.proposal.*;
import ^^.model.util.constants.*;
import ^^.cluster_anchoring;
import ^^.config.*;

// NB: check authority before calling this function
function internal_vote(provider, proposal, vote: boolean) {
    require(voter_set_member @? { proposal.voter_set, provider }, provider.pubkey + " must be a member of the voter set");
    create vote(proposal, provider, vote);
    log("vote added with value:", if (vote) "Yes" else "False");
    try_to_apply_proposal(proposal);
}

function try_to_apply_proposal(prop: proposal) {
    val prop_str = proposal_str(prop);
    val results = get_proposal_voting_results(prop.rowid);
    when (results.voting_result) {
        pending -> log("proposal is still under discussion:", prop_str);
        rejected -> {
            log("proposal rejected:", prop_str);
            delete_proposal(prop);
        }
        approved -> {
            log("proposal approved:", prop_str);
            apply_voting_result_handlers()[prop.proposal_type.name](prop);
            delete_proposal(prop);
        }
    }
}

@extendable function apply_other_voting_result(proposal) { /* Should be extended */ }

// TODO: Move implemetation to modules
@extendable function apply_voting_result_handlers(): map<text, (proposal) -> unit> = [
    proposal_type.configuration.name: apply_configuration(*),
    proposal_type.configuration_at.name: apply_configuration_at(*),
    proposal_type.bc.name: apply_bc(*),
    proposal_type.container_limits.name: apply_container_limits(*),
    proposal_type.cluster_limits.name: apply_cluster_limits(*),
    proposal_type.cluster_provider.name: apply_cluster_provider(*),
    proposal_type.cluster_remove.name: apply_remove_cluster(*),
    proposal_type.provider_state.name: apply_provider_state(*),
    proposal_type.provider_is_system.name: apply_provider_is_system(*),
    proposal_type.provider_quota.name: apply_provider_quota(*),
    proposal_type.provider_batch.name: apply_provider_batch(*),
    proposal_type.provider_remove.name: apply_remove_provider(*),
    proposal_type.blockchain_action.name: apply_blockchain_action(*),
    proposal_type.cluster_anchoring_configuration.name: apply_cluster_anchoring_configuration(*),
    proposal_type.other.name: apply_other_voting_result(*)
];

function apply_container_limits(proposal) {
    val pps = pending_container_limits @ { proposal };
    update container_resource_limit @ {pps.container, container_resource_limit_type.max_blockchains} (pps.max_blockchains);
    update container_resource_limit @ {pps.container, container_resource_limit_type.cpu} (pps.cpu);
    update container_resource_limit @ {pps.container, container_resource_limit_type.ram} (pps.ram);
    update container_resource_limit @ {pps.container, container_resource_limit_type.storage} (pps.storage);
    update container_resource_limit @ {pps.container, container_resource_limit_type.io_read} (pps.io_read);
    update container_resource_limit @ {pps.container, container_resource_limit_type.io_write} (pps.io_write);
}

function apply_cluster_limits(proposal) {
    val pps = pending_cluster_limits @ { proposal };
    update cluster_resource_limit @ {pps.cluster, cluster_resource_limit_type.max_containers} (pps.max_containers);
    update cluster_resource_limit @ {pps.cluster, cluster_resource_limit_type.default_container_max_blockchains} (pps.default_container_max_blockchains);
    update cluster_resource_limit @ {pps.cluster, cluster_resource_limit_type.default_container_cpu} (pps.default_container_cpu);
    update cluster_resource_limit @ {pps.cluster, cluster_resource_limit_type.default_container_ram} (pps.default_container_ram);
    update cluster_resource_limit @ {pps.cluster, cluster_resource_limit_type.default_container_storage} (pps.default_container_storage);
    update cluster_resource_limit @ {pps.cluster, cluster_resource_limit_type.default_container_io_read} (pps.default_container_io_read);
    update cluster_resource_limit @ {pps.cluster, cluster_resource_limit_type.default_container_io_write} (pps.default_container_io_write);
}

function apply_remove_cluster(proposal) {
    val cl = pending_remove_cluster @ { proposal } .cluster;
    delete pending_remove_cluster @ { proposal };
    remove_cluster_impl(cl);
}

function apply_cluster_provider(proposal) {
    val pps = pending_cluster_provider @ {proposal};
    if (pps.add) {
        create cluster_provider(pps.cluster, pps.provider);
    } else {
        delete cluster_provider @ {pps.cluster, pps.provider};
    }
}

// For promotion and demotion of system providers
function apply_provider_is_system(proposal) {
    val pps = pending_provider_is_system @ {proposal};

    // If promotion, update SYSTEM_P voter set
    if (pps.system) {
        enroll.system(pps.provider);
    } else {
        revoke.system(pps.provider);
    }
}

// For both enabling and disabling of providers:
function apply_provider_state(proposal) {
    val pps = pending_provider_state @ { proposal };
    update_provider_state(pps.provider, pps.active);
}

function update_provider_state(provider, active: boolean) {
    provider.active = active;
    if (active == false) {
        update node @* { provider } ( .active = false );
        // cluster nodes
        delete cluster_node @* { .node.provider == provider };
        for (cl in cluster_provider @* { provider } (.cluster)) {
            // Removing the last node of a cluster is not allowed:
            require(not(empty(cluster_node @* { cl })), "Cannot deactivate the last node of a cluster: " + cl.name);
            update_configuration_signers(cl);
        }
        // cluster replica nodes
        delete cluster_replica_node @* { .node.provider == provider };
        // blockchain replica nodes
        delete blockchain_replica_node @* { .node.provider == provider };
        // remove disabled provider from voter_set_member table
        delete voter_set_member @* { .provider == provider };
        // updating node list timestamp
        node_list.last_update = op_context.last_block_time;
    } else { // enable
        // If enabled provider is a system provider, update SYSTEM_P voter set
        if (roles.has_system_access(provider)) {
            create voter_set_member(voter_set @ { voter_sets.system_p }, provider);
        }
    }
}

function apply_provider_quota(proposal) {
    val ppq = pending_provider_quota @ { proposal };
    update provider_quota @? { ppq.provider_tier, ppq.provider_quota_type } (ppq.value);
}

function apply_provider_batch(proposal) {
    val ppb = pending_provider_batch @ { proposal };
    val providers = list<provider_info>.from_gtv(gtv.from_bytes(ppb.provider_infos));
    for (pi in providers) {
        if (empty(provider @? { pi.pubkey })) {
            register_and_enable_provider(pi, ppb.provider_tier, null, null, ppb.active);
            when {
                ppb.system -> {
                    val provider = provider @ { pi.pubkey };
                    enroll.system(provider);
                    if (not(ppb.active)) {
                        update_provider_state(provider, false);
                    }
                }
                _is_node_provider(ppb.provider_tier) -> enroll.node(provider @ { pi.pubkey });
            }
        } else {
            log("Warning: provider already exists: " + pi.pubkey);
        }
    }
}

function apply_remove_provider(proposal) {
    val provider = pending_remove_provider @ { proposal } (.provider);
    delete node @* { provider };
    delete cluster_provider @* { provider };
    delete provider_rl_state @* { provider };
    delete pending_remove_provider @ { proposal };
    delete provider;
}

function apply_configuration(proposal) {
    val pc = pending_configuration @ { proposal };
    val is_chain0 = pc.blockchain.rid == chain_context.blockchain_rid;

    if (is_chain0) {
        apply_configuration_chain0(pc);
    } else if (pcu_enabled()) {
        apply_configuration_pcu(pc);
    } else {
        apply_configuration_legacy(pc);
    }
}

function apply_configuration_chain0(pc: pending_configuration) {
    val apply_at_height = op_context.block_height + 1;
    log("Base configuration update chain0 at height %d".format(apply_at_height));
    require(empty(blockchain_configuration @? { pc.blockchain, apply_at_height }), "Configuration at height %d already exists".format(apply_at_height));
    create blockchain_configuration(pc.blockchain, apply_at_height, pc.data);
    add_dependencies(pc.data, pc.blockchain.rid, apply_at_height);
}

function apply_configuration_pcu(pc: pending_configuration) {
    val base_config = pc.data;

    val last_configuration_height = (blockchain_configuration @? { pc.blockchain } (@sort_desc .height) limit 1) ?: 0;
    val last_pending_configuration = pending_blockchain_configuration @? { pc.blockchain } (@sort_desc @omit .minimum_height, $) limit 1;
    val (minimum_height, signers) = if (last_pending_configuration != null)
        (last_configuration_height.max(last_pending_configuration.minimum_height) + 1,
         last_pending_configuration.signers)
     else
        (last_configuration_height + 1,
         blockchain_configuration_signers @ { pc.blockchain } (@omit @sort_desc .height, .signers) limit 1);
    log("Base configuration update with PCU for chain %s at minimum height %d".format(pc.blockchain.rid, minimum_height));
    val full_config = map<text, gtv>.from_gtv(gtv.from_bytes(base_config));
    full_config["signers"] = gtv.from_bytes(signers);
    create pending_blockchain_configuration(
        pc.blockchain,
        minimum_height,
        config_hash=full_config.to_gtv().hash(),
        base_config,
        signers
    );
}

function apply_configuration_legacy(pc: pending_configuration) {
    val apply_at_height = get_last_height(pc.blockchain) + 10;
    log("Base configuration update without PCU for chain %s at height %d".format(pc.blockchain.rid, apply_at_height));
    require(empty(blockchain_configuration @? { pc.blockchain, apply_at_height }), "Configuration at height %d already exists".format(apply_at_height));
    create blockchain_configuration(pc.blockchain, apply_at_height, pc.data);
    add_dependencies(pc.data, pc.blockchain.rid, apply_at_height);
}

function apply_configuration_at(proposal) {
    val pc = pending_configuration_at @ { proposal };

    val last_height = get_last_height(pc.blockchain);
    val cant_apply_message = "Proposed configuration for height %d can't be applied, current height: %d".format(pc.height, last_height);
    if (pc.force) {
        if (pc.height != -1) {
            require(last_height < pc.height, cant_apply_message);
        }
    } else {
        require(last_height < pc.height, cant_apply_message);
        require(empty(blockchain_configuration @? { pc.blockchain, pc.height } limit 1), "Configuration at height %d already exists for blockchain %s".format(pc.height, pc.blockchain.rid));
    }

    val height = if (pc.height == -1) last_height + 1 else pc.height;

    if (not(exists(blockchain_configuration @? { pc.blockchain, height }))) {
        create blockchain_configuration(pc.blockchain, height, data = pc.data);
        add_dependencies(pc.data, pc.blockchain.rid, height);
    } else {
        update blockchain_configuration @ { pc.blockchain, height } ( .data = pc.data );
    }
}

// Initial signers of new bc are the ones in cluster_node table.
function apply_bc(proposal) {
    val bc = pending_blockchain @ {proposal};

    val nodes = cluster_node @* { bc.container.cluster } (@sort .node.pubkey);
    // do not write new configuration when size is 0 since it's impossible to recover from that
    require(nodes.size() > 0, "Cluster must have at least one node");

    val blockchain_rid = add_blockchain(bc.data, nodes.to_gtv().to_bytes(), bc.name, bc.container);
    log("Added blockchain", blockchain_rid);
}

function apply_blockchain_action(proposal) {
    val pba = pending_blockchain_action @ { proposal };
    when (pba.action) {
        pause -> _apply_pause_blockchain(pba, proposal);
        resume -> _apply_resume_blockchain(pba, proposal);
        remove -> _apply_delete_blockchain(pba, proposal);
    }
}

function apply_cluster_anchoring_configuration(proposal) {
    val ac = pending_cluster_anchoring_configuration @ { proposal };
    cluster_anchoring.set_config(ac.data);
}

// Stop block production by inactivating bc, and keep replicas.
function _apply_pause_blockchain(action: pending_blockchain_action, proposal) {
    update blockchain @ { action.blockchain.rid } (.active = false);
    // Keep replicas
    for (signer in get_blockchain_signers(action.blockchain.rid)) {
        create blockchain_replica_node(action.blockchain, node @ { signer[0] });
    }
}

// Restart block production; block builders will be the ones in cluster_node.
function _apply_resume_blockchain(action: pending_blockchain_action, proposal) {
    update blockchain @ { action.blockchain.rid } (.active = true);
    // Removing replicas if they are cluster nodes
    val nodes = get_blockchain_signers(action.blockchain.rid);
    for (node_info in nodes) {
        delete blockchain_replica_node @? { action.blockchain, node @ { node_info[0] } };
    }
}

// Delete everything about this bc
function _apply_delete_blockchain(action: pending_blockchain_action, proposal) {
    val bc = action.blockchain;
    before_delete_blockchain(bc);
    delete container_blockchain @ { bc };
    delete blockchain_configuration @* { bc };
    delete blockchain_configuration_signers @* { bc };
    delete blockchain_added @* { bc };
    delete blockchain_replica_node @* { bc };
    delete blockchain_dependency @* { .me == bc };
    delete pending_blockchain_action @ { proposal };
    delete blockchain @ { bc.rid };
}

function proposal_str(prop: proposal) {
    return "%s:%d".format(prop.proposal_type, prop.rowid);
}

@extendable function before_delete_blockchain(blockchain) {}
