function create_cluster_impl(
        me: provider, name, governor: voter_set, providers: list<pubkey>,
        cluster_units: integer = standard_cluster_defaults.cluster_units
    ) {
    require(empty(cluster @* { name }), "Cluster with name %s already exists".format(name));
    require(cluster_units > 0, "Cluster must have at least 1 cluster unit");
    val c = create cluster(name, governor, false, cluster_units);

    for (p_key in providers) {
        val provider = require_provider(p_key);
        require_node_access(provider);
        create cluster_provider(c, provider);
    }

    create_system_container(
        me,
        system_container_name(c.name),
        cluster = c,
        voter_set = governor
    );

    after_cluster_creation(me, c);
    return c;
}

function require_cluster_quotas(cluster, wanted_container_units: integer) {
    if (wanted_container_units < 1) return;
    val available_container_units = get_available_container_units(cluster);
    require(wanted_container_units <= available_container_units,
        "Can not propose container, cluster %s has %d available container units but wanted %d".format(cluster.name, available_container_units, wanted_container_units));
}

function get_available_container_units(cluster): integer {
    val max_container_units = get_max_container_units_for_cluster(cluster);
    val used_container_units = get_used_container_units(cluster);
    return max_container_units - used_container_units;
}

function get_max_container_units_for_cluster(cluster): integer {
    return standard_cluster_unit.container_units * cluster.cluster_units;
}

function get_used_container_units(cluster): integer {
    return container_resource_limit @ {
        .container.cluster == cluster,
        container_resource_limit_type.container_units
    } (@sum .value);
}

function get_minimum_cluster_units_for_current_container_units(cluster): integer {
    val currently_used_container_units = get_used_container_units(cluster);
    return currently_used_container_units / standard_cluster_unit.container_units + 1;
}

function _add_replica_node_to_cluster_internal(cluster, node) {
    require_cluster_units_for_node(cluster, node);
    create cluster_replica_node(cluster, node);
}

function _remove_replica_node_from_cluster_internal(node) {
    delete cluster_replica_node @* { node };
}

/**
 * When all providers have provided a node each, cluster goes operational and stays operational even if a provider is added to the cluster
 */
function check_operational(cl: cluster) {
    val providers = cluster_provider @* { cl }.provider;
    val nodes = cluster_node @* { cl }.node;
    if (nodes.size() == providers.size()) {
        update cluster @ { cl.name } (.operational = true);
        after_cluster_operational(cl);
    }
}

/**
 * If a provider is part of that cluster, and if provider do not already have a node in this cluster,
 * add node as block signer to this cluster. blockchain_configuration_signers update is included.
 */
function add_node_to_cluster_internal(provider, node, cluster) {
    if (exists(cluster_node @? { cluster, node })) {
        log("Node %s already is part of cluster %s".format(node.pubkey, cluster.name));
        return;
    }

    if (exists(cluster_provider @* { cluster, provider })) {
        val provider_cluster_nodes = cluster_node @* { cluster, .node in node @* { provider } };
        require(empty(provider_cluster_nodes), "A provider can only provide one node to each cluster");
        _remove_replica_node_from_cluster_internal(node);
        require_cluster_units_for_node(cluster, node);
        create cluster_node(cluster, node);
        if (pcu_enabled()) {
            pcu_update_configuration_signers(cluster, null);
        } else {
            update_configuration_signers(cluster);
        }
        // check if cluster now is operational, if so update the flag:
        check_operational(cluster);
        log("blockchain configuration signers are updated");
        after_node_added_to_cluster(cluster, node);
    } else {
        log("Provider %s is not a member of cluster %s".format(provider.pubkey, cluster.name));
    }
}

// Use this to update signers after a change in cluster_node table.
function pcu_update_configuration_signers(cluster, excluded_node: node?) {
    val signers = cluster_node @* { cluster } (@sort .node.pubkey);
    // do not write new configuration when size is 0 since it's impossible to recover from that
    require(signers.size() > 0);

    val bcs = container_blockchain @* { .container.cluster == cluster } .blockchain;
    for (blockchain in bcs) {
        val is_chain0 = blockchain.rid == chain_context.blockchain_rid;
        if (is_chain0) {
            update_configuration_signers_chain0(blockchain, signers);
        } else {
            update_configuration_signers_pcu(blockchain, signers, excluded_node?.pubkey);
        }
    }
}

function update_configuration_signers(cluster) {
    val signers = cluster_node @* { cluster } (@sort .node.pubkey);
    // do not write new configuration when size is 0 since it's impossible to recover from that
    require(signers.size() > 0);

    val bcs = container_blockchain @* { .container.cluster == cluster } .blockchain;
    for (blockchain in bcs) {
        val is_chain0 = blockchain.rid == chain_context.blockchain_rid;
        if (is_chain0) {
            update_configuration_signers_chain0(blockchain, signers);
        } else {
            update_configuration_signers_legacy(blockchain, signers);
        }
    }
}

function update_configuration_signers_chain0(blockchain, signers: list<pubkey>) {
    val height = op_context.block_height + 1;
    log("Signers update for chain0 at height %d: %s".format(height, signers));
    val bc_signers = blockchain_configuration_signers @? { blockchain, height };
    if (bc_signers == null) {
        create blockchain_configuration_signers(blockchain, height, signers.to_gtv().to_bytes());
    } else {
        bc_signers.signers = signers.to_gtv().to_bytes();
    }
}

function update_configuration_signers_pcu(blockchain, signers: list<pubkey>, excluded_signer: pubkey?) {
    val last_signers_config = blockchain_configuration_signers @? { blockchain } (@sort_desc .height, .signers) limit 1;

    if (last_signers_config == null) {
        // No initial signers config found, add new config as initial
        create blockchain_configuration_signers(blockchain, 0, signers.to_gtv().to_bytes());
        return;
    }

    val last_pending_config = pending_blockchain_configuration @? { blockchain } (@sort_desc @omit .minimum_height, $) limit 1;
    val (minimum_height, base_config, last_signers) = if (last_pending_config != null) (
        last_signers_config.height.max(last_pending_config.minimum_height) + 1,
        last_pending_config.base_config,
        last_pending_config.signers
    ) else (
        last_signers_config.height + 1,
        blockchain_configuration @ { blockchain } (@omit @sort_desc .height, .data) limit 1,
        last_signers_config.signers
    );

    if (signers.to_gtv().to_bytes() == last_signers) {
        log("Signers update for chain %s not necessary, already %s".format(blockchain.rid, signers));
        return;
    }

    log("Signers update with PCU for chain %s at minimum height %d: %s".format(blockchain.rid, minimum_height, signers));
    val full_config = map<text, gtv>.from_gtv(gtv.from_bytes(base_config));
    full_config["signers"] = signers.to_gtv();
    val config_hash = full_config.to_gtv().hash();
    create pending_blockchain_configuration(
        blockchain,
        minimum_height,
        config_hash = config_hash,
        base_config,
        signers = signers.to_gtv().to_bytes()
    );

    if (excluded_signer != null) {
        create signer_excluded_from_pending_configuration(
            blockchain,
            config_hash = config_hash,
            pubkey = excluded_signer
        );
    }
}

function update_configuration_signers_legacy(blockchain, signers: list<pubkey>) {
    val height = get_last_height(blockchain) + 5;
    log("Signers update without PCU for chain %s at height %d: %s".format(blockchain.rid, height, signers));
    val bc_signers = blockchain_configuration_signers @? { blockchain, height };
    if (bc_signers == null) {
        create blockchain_configuration_signers(blockchain, height, signers.to_gtv().to_bytes());
    } else {
        bc_signers.signers = signers.to_gtv().to_bytes();
    }
}

function require_cluster_available_for_removal(cluster) {
    require(cluster.name != clusters.system, "System cluster can't be deleted");
    require(
        empty(container @* { cluster, .system == false }),
        "Cluster %s is not empty and can't be deleted. Delete containers first".format(cluster.name)
    );
}

function get_cluster_for_blockchain(blockchain_rid: byte_array): cluster {
    return (container_blockchain, blockchain) @ { blockchain.rid == blockchain_rid, blockchain == container_blockchain.blockchain }
                 ( container_blockchain.container.cluster );
}

function remove_cluster_impl(cluster) {
    before_cluster_removal(cluster);
    delete cluster_node @* { cluster };
    delete cluster_replica_node @* { cluster };
    delete cluster_provider @* { cluster };
    delete cluster;
}

@extendable function before_cluster_removal(cluster) {}

@extendable function after_cluster_creation(provider, cluster) {}

@extendable function after_cluster_operational(cluster) {}

@extendable function after_node_added_to_cluster(cluster, node) {}
