function create_cluster_impl(me: provider, name, governor: voter_set, providers: list<pubkey>, max_containers: integer = -1, cpu: integer = -1, ram: integer = -1, storage: integer = -1, io_read: integer = -1, io_write: integer = -1) {
    require(empty(cluster @* { name }), "Cluster with name %s already exists".format(name));
    val c = create cluster(name, governor);
    create cluster_resource_limit(c, cluster_resource_limit_type.max_containers , max_containers);
    create cluster_resource_limit(c, cluster_resource_limit_type.default_container_max_blockchains, -1);
    create cluster_resource_limit(c, cluster_resource_limit_type.default_container_cpu, cpu);
    create cluster_resource_limit(c, cluster_resource_limit_type.default_container_ram, ram);
    create cluster_resource_limit(c, cluster_resource_limit_type.default_container_storage, storage);
    create cluster_resource_limit(c, cluster_resource_limit_type.default_container_io_read, io_read);
    create cluster_resource_limit(c, cluster_resource_limit_type.default_container_io_write, io_write);
    for (p_key in providers) {
        val provider = require_provider(p_key);
        require_node_access(provider);
        create cluster_provider(c, provider);
    }

    create_system_container(
        me,
        system_container_name(c.name),
        cluster = c,
        voter_set = governor
    );

    after_cluster_creation(me, c);
    return c;
}

function require_cluster_quotas(cluster) {
    val max_containers = cluster_resource_limit @? { cluster, cluster_resource_limit_type.max_containers } (.value);
    if (max_containers != null and max_containers != -1) {
        val cluster_container_count = container @ { cluster, .system == false } (@sum 1);
        require(cluster_container_count < max_containers, "Can't propose container, cluster %s is full".format(cluster.name));
    }
}

function _add_replica_node_to_cluster_internal(cluster, node) {
    create cluster_replica_node(cluster, node);
}

function _remove_replica_node_from_cluster_internal(node) {
    delete cluster_replica_node @* { node };
}

/**
 * When all providers have provided a node each, cluster goes operational and stays operational even if a provider is added to the cluster
 */
function check_operational(cl: cluster) {
    val providers = cluster_provider @* { cl }.provider;
    val nodes = cluster_node @* { cl }.node;
    if (nodes.size() == providers.size()) {
        update cluster @ { cl.name } (.operational = true);
        after_cluster_operational(cl);
    }
}

/**
 * If a provider is part of that cluster, and if provider do not already have a node in this cluster,
 * add node as block signer to this cluster. blockchain_configuration_signers update is included.
 */
function add_node_to_cluster_internal(provider, node, cluster) {
    if (exists(cluster_node @? { cluster, node })) {
        log("Node %s already is part of cluster %s".format(node.pubkey, cluster.name));
        return;
    }

    if (exists(cluster_provider @* { cluster, provider })) {
        val provider_cluster_nodes = cluster_node @* { cluster, .node in node @* { provider } };
        require(empty(provider_cluster_nodes), "A provider can only provide one node to each cluster");
        create cluster_node(cluster, node);
        if (pcu_enabled()) {
            pcu_update_configuration_signers(cluster, null);
        } else {
            update_configuration_signers(cluster);
        }
        _remove_replica_node_from_cluster_internal(node);
        // check if cluster now is operational, if so update the flag:
        check_operational(cluster);
        log("blockchain configuration signers are updated");
        after_node_added_to_cluster(cluster, node);
    } else {
        log("Provider %s is not a member of cluster %s".format(provider.pubkey, cluster.name));
    }
}

// Use this to update signers after a change in cluster_node table.
function pcu_update_configuration_signers(cluster, excluded_node: node?) {
    val signers = cluster_node @* { cluster } (@sort .node.pubkey);
    // do not write new configuration when size is 0 since it's impossible to recover from that
    require(signers.size() > 0);

    val bcs = container_blockchain @* { .container.cluster == cluster } .blockchain;
    for (blockchain in bcs) {
        val is_chain0 = blockchain.rid == chain_context.blockchain_rid;
        if (is_chain0) {
            update_configuration_signers_chain0(blockchain, signers);
        } else {
            update_configuration_signers_pcu(blockchain, signers, excluded_node?.pubkey);
        }
    }
}

function update_configuration_signers(cluster) {
    val signers = cluster_node @* { cluster } (@sort .node.pubkey);
    // do not write new configuration when size is 0 since it's impossible to recover from that
    require(signers.size() > 0);

    val bcs = container_blockchain @* { .container.cluster == cluster } .blockchain;
    for (blockchain in bcs) {
        val is_chain0 = blockchain.rid == chain_context.blockchain_rid;
        if (is_chain0) {
            update_configuration_signers_chain0_legacy(blockchain, signers);
        } else {
            update_configuration_signers_legacy(blockchain, signers);
        }
    }
}

function update_configuration_signers_chain0(blockchain, signers: list<pubkey>) {
    val height = op_context.block_height + 1; // NB: compute_blockchain_info_list()/get_cluster_node_blockchains() relies on this
    log("Signers update for chain0 at height %d: %s".format(height, signers));

    // make a base_config at `height` unique
    if (empty(blockchain_configuration @? { blockchain, height })) {
        val base_config = blockchain_configuration @? { blockchain, .height < height } (@omit @sort_desc .height, .data) limit 1;
        val unique_base_config = make_config_unique(base_config!!);
        create blockchain_configuration(blockchain, height, unique_base_config);
        add_dependencies(unique_base_config, blockchain.rid, height);
    }

    // signers
    val bc_signers = blockchain_configuration_signers @? { blockchain, height };
    if (bc_signers == null) {
        create blockchain_configuration_signers(blockchain, height, signers.to_gtv().to_bytes());
    } else {
        bc_signers.signers = signers.to_gtv().to_bytes();
    }
}

function update_configuration_signers_pcu(blockchain, signers: list<pubkey>, excluded_signer: pubkey?) {
    val last_signers_config = blockchain_configuration_signers @? { blockchain } (@sort_desc .height, .signers) limit 1;

    if (last_signers_config == null) {
        // No initial signers config found, add new config as initial
        create blockchain_configuration_signers(blockchain, 0, signers.to_gtv().to_bytes());
        return;
    }

    val last_pending_config = pending_blockchain_configuration @? { blockchain } (@sort_desc @omit .minimum_height, $) limit 1;
    val (minimum_height, base_config, last_signers) = if (last_pending_config != null) (
        last_signers_config.height.max(last_pending_config.minimum_height) + 1,
        last_pending_config.base_config,
        last_pending_config.signers
    ) else (
        last_signers_config.height + 1,
        blockchain_configuration @ { blockchain } (@omit @sort_desc .height, .data) limit 1,
        last_signers_config.signers
    );

    if (signers.to_gtv().to_bytes() == last_signers) {
        log("Signers update for chain %s not necessary, already %s".format(blockchain.rid, signers));
        return;
    }

    log("Signers update with PCU for chain %s at minimum height %d: %s".format(blockchain.rid, minimum_height, signers));
    val unique_base_config = make_config_unique(base_config);
    val full_config = map<text, gtv>.from_gtv(gtv.from_bytes(unique_base_config));
    full_config["signers"] = signers.to_gtv();
    val config_hash = full_config.to_gtv().hash();
    create pending_blockchain_configuration(
        blockchain,
        minimum_height,
        config_hash = config_hash,
        base_config = unique_base_config,
        signers = signers.to_gtv().to_bytes()
    );

    if (excluded_signer != null) {
        create signer_excluded_from_pending_configuration(
            blockchain,
            config_hash = config_hash,
            pubkey = excluded_signer
        );
    }
}

function update_configuration_signers_chain0_legacy(blockchain, signers: list<pubkey>) {
    val height = op_context.block_height + 1;
    log("Signers update for chain0 at height %d: %s".format(height, signers));
    val bc_signers = blockchain_configuration_signers @? { blockchain, height };
    if (bc_signers == null) {
        create blockchain_configuration_signers(blockchain, height, signers.to_gtv().to_bytes());
    } else {
        bc_signers.signers = signers.to_gtv().to_bytes();
    }
}

function update_configuration_signers_legacy(blockchain, signers: list<pubkey>) {
    val height = get_last_height(blockchain) + 5;
    log("Signers update without PCU for chain %s at height %d: %s".format(blockchain.rid, height, signers));
    val bc_signers = blockchain_configuration_signers @? { blockchain, height };
    if (bc_signers == null) {
        create blockchain_configuration_signers(blockchain, height, signers.to_gtv().to_bytes());
    } else {
        bc_signers.signers = signers.to_gtv().to_bytes();
    }
}

function require_cluster_available_for_removal(cluster) {
    require(cluster.name != clusters.system, "System cluster can't be deleted");
    require(
        empty(container @* { cluster, .system == false }),
        "Cluster %s is not empty and can't be deleted. Delete containers first".format(cluster.name)
    );
}

function get_cluster_for_blockchain(blockchain_rid: byte_array): cluster {
    return (container_blockchain, blockchain) @ { blockchain.rid == blockchain_rid, blockchain == container_blockchain.blockchain }
                 ( container_blockchain.container.cluster );
}

function remove_cluster_impl(cluster) {
    before_cluster_removal(cluster);
    delete cluster_resource_limit @* { cluster };
    delete cluster_node @* { cluster };
    delete cluster_replica_node @* { cluster };
    delete cluster_provider @* { cluster };
    delete cluster;
}

@extendable function before_cluster_removal(cluster) {}

@extendable function after_cluster_creation(provider, cluster) {}

@extendable function after_cluster_operational(cluster) {}

@extendable function after_node_added_to_cluster(cluster, node) {}
