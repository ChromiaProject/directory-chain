@test module;

import ^.config_test_helpers.*;
import ^^.*;
import ^^.test.setup.*;
import ^^.test.util.constants.*;
import proposal_blockchain.*;
import direct_container.*;

function test_configuration_is_compressed_on_creation_and_update() {
    setup_module(cluster_anchoring_config = ["any": "value".to_gtv()]);
    val cluster = require_cluster(clusters.system);
    val anchor_chain = cluster_anchoring_chain @ { cluster } (.blockchain);

    val content_to_compress = "Compress me!".to_gtv();
    val config0 = [
        "compressed_roots": [compressed_root(
            path = ["compression_content"],
            compressed_keys = []
        )].to_gtv_pretty(),
        "compression_content": [
            "some_content": content_to_compress
        ].to_gtv_pretty(),
        "config_consensus_strategy": "HEADER_HASH".to_gtv(),
        "blockstrategy": ["mininterblockinterval": (1000).to_gtv()].to_gtv()
    ];

    rell.test.tx().op(
        create_container(initial_provider.pub, "container", clusters.system, 0, [initial_provider.pub]),
        propose_blockchain(initial_provider.pub, config0.to_gtv_pretty().to_bytes(), "foo_chain", "container", "")
    ).sign(initial_provider).run();

    assert_not_null(compressed_blockchain_configuration_part @? { .hash == content_to_compress.hash() });

    val blockchain = blockchain @ { "foo_chain" };
    val bc_rid = blockchain.rid;
    val compressed_configuration_data = blockchain_configuration @ { blockchain, .height == 0 }.data;

    val compressed_config = map<text,gtv>.from_gtv(gtv.from_bytes(compressed_configuration_data));
    assert_false(map<text,gtv>.from_gtv(compressed_config["compression_content"]).contains("some_content"));

    val decompressed_configuration_data = get_blockchain_configuration(blockchain.rid, 0)!!.base_config;
    val decompressed_config = map<text,gtv>.from_gtv(gtv.from_bytes(decompressed_configuration_data));
    assert_equals(map<text,gtv>.from_gtv(decompressed_config["compression_content"])["some_content"], content_to_compress);

    // Attempt update
    val new_content_to_compress = "Compress me as well!".to_gtv();
    val config1 = [
        "compressed_roots": [compressed_root(
            path = ["compression_content"],
            compressed_keys = [compressed_key(
                content_key = "some_content",
                content_hash = content_to_compress.hash()
            )]
        )].to_gtv_pretty(),
        "compression_content": [
            "some_new_content": new_content_to_compress
        ].to_gtv_pretty(),
        "config_consensus_strategy": "HEADER_HASH".to_gtv(),
        "blockstrategy": ["mininterblockinterval": (1000).to_gtv()].to_gtv()
    ];

    rell.test.tx().op(
        propose_configuration(initial_provider.pub, bc_rid, config1.to_gtv_pretty().to_bytes(), "")
    ).sign(initial_provider).run();

    val pending_config1 = get_pending_blockchain_configuration(blockchain, 5)[0];
    val full_config1 = map<text, gtv>.from_gtv(gtv.from_bytes(pending_config1.base_config));
    full_config1["signers"] = pending_config1.signers.to_gtv();
    val pending_config1_hash = full_config1.to_gtv().hash();

    rell.test.tx().op(
        receive_configuration_updated_op(
            anchor_chain.rid,
            configuration_updated_topic,
            configuration_updated(
                blockchain_rid=bc_rid,
                height=5,
                config_hash=pending_config1_hash
            ).to_gtv()
        )
    ).run();

    val updated_compressed_configuration_data = blockchain_configuration @ { blockchain, .height == 5 }.data;

    val updated_compressed_config = map<text,gtv>.from_gtv(gtv.from_bytes(updated_compressed_configuration_data));
    val compression_content_map = map<text,gtv>.from_gtv(updated_compressed_config["compression_content"]);
    assert_false(updated_compressed_config.contains("some_content"));
    assert_false(updated_compressed_config.contains("some_new_content"));

    val updated_decompressed_configuration_data = get_blockchain_configuration(blockchain.rid, 5)!!.base_config;
    val updated_decompressed_config = map<text,gtv>.from_gtv(gtv.from_bytes(updated_decompressed_configuration_data));
    val decompressed_compression_content_map = map<text,gtv>.from_gtv(updated_decompressed_config["compression_content"]);
    assert_equals(decompressed_compression_content_map["some_content"], content_to_compress);
    assert_equals(decompressed_compression_content_map["some_new_content"], new_content_to_compress);
}

function test_configuration_compression_path_restriction() {
    setup_module();

    val content_to_compress = "Compress me!".to_gtv();
    val config_invalid_depth = [
        "compressed_roots": [compressed_root(
            path = ["1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11"],
            compressed_keys = []
        )].to_gtv_pretty(),
        "compression_content": [
            "some_content": content_to_compress
        ].to_gtv_pretty(),
        "config_consensus_strategy": "HEADER_HASH".to_gtv(),
        "blockstrategy": ["mininterblockinterval": (1000).to_gtv()].to_gtv()
    ];

    rell.test.tx().op(
        create_container(initial_provider.pub, "container", clusters.system, 0, [initial_provider.pub]),
        propose_blockchain(initial_provider.pub, config_invalid_depth.to_gtv_pretty().to_bytes(), "foo_chain", "container", "")
    ).sign(initial_provider).run_must_fail("Compression path depth 11 exceeds maximum allowed depth 10");
}

function test_configuration_compression_size_restriction() {
    setup_module(cluster_anchoring_config = ["any": "value".to_gtv()]);
    val cluster = require_cluster(clusters.system);
    val anchor_chain = cluster_anchoring_chain @ { cluster } (.blockchain);

    val content_to_compress = "A".repeat(1000).to_gtv();
    val config0 = [
        "compressed_roots": [compressed_root(
            path = ["compression_content"],
            compressed_keys = []
        )].to_gtv_pretty(),
        "compression_content": [
            "some_content": content_to_compress
        ].to_gtv_pretty(),
        "config_consensus_strategy": "HEADER_HASH".to_gtv(),
        "blockstrategy": ["mininterblockinterval": (1000).to_gtv()].to_gtv()
    ];

    rell.test.tx().op(
        create_container(initial_provider.pub, "container", clusters.system, 0, [initial_provider.pub]),
        propose_blockchain(initial_provider.pub, config0.to_gtv_pretty().to_bytes(), "foo_chain", "container", "")
    ).sign(initial_provider).run();

    val blockchain = blockchain @ { "foo_chain" };
    val bc_rid = blockchain.rid;

    val compressed_keys = list<compressed_key>();
    // Inject compressed content enough times to exceed config max size
    for (i in range(11)) {
        compressed_keys.add(compressed_key(
            content_key = "some_content" + i,
            content_hash = content_to_compress.hash()
        ));
    }

    val config_invalid_size = [
        "compressed_roots": [compressed_root(
            path = ["compression_content"],
            compressed_keys
        )].to_gtv_pretty(),
        "compression_content": map<text, gtv>().to_gtv(),
        "config_consensus_strategy": "HEADER_HASH".to_gtv(),
        "blockstrategy": ["mininterblockinterval": (1000).to_gtv()].to_gtv()
    ];

    rell.test.tx().op(
        propose_configuration(initial_provider.pub, bc_rid, config_invalid_size.to_gtv_pretty().to_bytes(), "")
    ).sign(initial_provider).run_must_fail("Configuration exceeds maximum allowed size");
}

function test_ambiguous_compressed_configuration() {
    setup_module(cluster_anchoring_config = ["any": "value".to_gtv()]);
    val cluster = require_cluster(clusters.system);
    val anchor_chain = cluster_anchoring_chain @ { cluster } (.blockchain);

    val content_to_compress = "Compress me!".to_gtv();
    val config0 = [
        "compressed_roots": [compressed_root(
            path = ["compression_content"],
            compressed_keys = []
        )].to_gtv_pretty(),
        "compression_content": [
            "some_content": content_to_compress
        ].to_gtv_pretty(),
        "config_consensus_strategy": "HEADER_HASH".to_gtv(),
        "blockstrategy": ["mininterblockinterval": (1000).to_gtv()].to_gtv()
    ];

    rell.test.tx().op(
        create_container(initial_provider.pub, "container", clusters.system, 0, [initial_provider.pub]),
        propose_blockchain(initial_provider.pub, config0.to_gtv_pretty().to_bytes(), "foo_chain", "container", "")
    ).sign(initial_provider).run();

    val blockchain = blockchain @ { "foo_chain" };
    val bc_rid = blockchain.rid;

    val new_content = "Something new".to_gtv();
    val ambiguous_config = [
        "compressed_roots": [compressed_root(
            path = ["compression_content"],
            compressed_keys = [compressed_key(
                content_key = "some_content",
                content_hash = content_to_compress.hash()
            )]
        )].to_gtv_pretty(),
        "compression_content": [
            "some_content": new_content
        ].to_gtv_pretty(),
        "config_consensus_strategy": "HEADER_HASH".to_gtv(),
        "blockstrategy": ["mininterblockinterval": (1000).to_gtv()].to_gtv()
    ];

    rell.test.tx().op(
        propose_configuration(initial_provider.pub, bc_rid, ambiguous_config.to_gtv_pretty().to_bytes(), "")
    )
    .sign(initial_provider)
    .run_must_fail("Ambiguous compression detected for path [compression_content], key 'some_content' is defined with different values in compression root and actual configuration");
}
